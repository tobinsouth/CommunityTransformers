<!DOCTYPE HTML>
<html>

<head>
  <title>Community Transformers</title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
  <link rel="stylesheet" href="assets/css/style.css" />
  <noscript>
	<link rel="stylesheet" href="assets/css/noscript.css" />
  </noscript>
  <script src="https://cdn.tailwindcss.com"></script>
  <script defer src="https://use.fontawesome.com/releases/v6.3.0/js/all.js"></script>
</head>

<body class="is-preload">

  <!-- Wrapper -->
  <div id="wrapper">

	<!-- Header -->
	<header id="header" class="alt">
	  <span class="logo"><img src="images/logoWhite.svg" alt="" class="w-1/4 md:w-1/3" /></span>
	  <h1>Community Transformers</h1>
	  <p>Securely Using Private Community Data With Foundation Models</p>
	  <p><em>a project of MIT Connection Science</em></p>
	</header>

	<!-- Nav
	<nav id="nav">
	  <ul>
		<li><a href="#intro" class="active">Abstract</a></li>
		<li><a href="#architecture">Architecture</a></li>
		<li><a href="#safety">Safety & Privacy</a></li>
		<li><a href="#next">Next Steps</a></li>
	  </ul>
	</nav> -->

	<!-- Main -->
	<div id="main">

	  <!-- Introduction -->
	  <section id="intro" class="main special">
		<div class="spotlight">
		  <div class="content">
			<div style="text-align: justify;">
			  <p>
				Large Language Models (LLMs) such as ChatGPT and LLaMA have demonstrated immense
				potential in various applications. However, ensuring that these models can be augmented with relevant contextual or business data safely and securely is critical to capitalizing on the diverse data created by individuals and organizations, and making sure that the benefits of LLMs are shared equitably.
			  </p>
			  <br />
			  <p>
				This body of work focuses on both technical and legal / policy solutions, addressing problems from winner-take-all model dynamics to cryptographically secure private retrieval augmented generation. 
			  </p>
			</div> 
			<br/>
			<header class="major">
				<h1 class="text-lg" style=" font-size:1.5rem">Read the papers </h1>
			</header>
			<div class="card-container">
				<div class="card">
					<h2 class="card-title">Secure Community Transformers: Private Pooled Data for LLMs
					</h2>
					<figure><img src="images/diagramV2black.svg" alt="Technical Diagram"></figure>
					<a href="SecureCommunityTransfomersMITSouth.pdf" class="button">Read the Whitepaper</a>
					<p>The paper discusses how large language models (LLMs) can effectively utilize small-scale data for insights across various sectors like consulting, education, healthcare, and law. It presents a framework for navigating trade-offs related to privacy, performance, and transparency, and argues that retrieval augmented generation (RAG) provides a more flexible, efficient, and auditable approach than traditional fine-tuning methods.
					</p>
					<br/>
					<p><em>Tobin South, Guy Zyskind, Robert Mahari, Alex 'Sandy' Pentland</em></p>
				</div>
				<div class="card">
					<h2 class="card-title">Private Retrieval Augmented Generation (PRAG): A Technology for Securely Using Private Data
					</h2>
					<figure><img src="images/PRAG_IVF_diagram.png" alt="Technical Diagram"></figure>
					<a href="https://openreview.net/pdf?id=JTcaziw7G1" class="button">Article in ICLR Submission</a>
					<p>The paper introduces Private Retrieval Augmented Generation (PRAG), a novel method that uses multi-party computation to securely fetch information from distributed databases for use in large language models without compromising privacy. It also presents a new MPC-friendly protocol for inverted file search, enabling fast and private document retrieval in a decentralized manner.</p>
					<br/>
					<p><em>Guy Zyskind*, Tobin South*, Alex 'Sandy' Pentland</em></p>
				</div>
				<div class="card">
					<h2 class="card-title">Legal Perspective on Auditability and Updateability
					</h2>
					<figure><img src="images/NLR_DALLE.png" alt="Technical Diagram"></figure>
					<a href="https://www.networklawreview.org/computational-three/" class="button">Article in Network Law Review</a>
					<p>A key design element of the Secure Community Transformers project is the ability for models to be auditable and updatable, key requirements in the wake of GDPR and CCPA. This builds into a framework of transparency by design, a topic that is explored from a legal perspective in the piece published in Network Law Review below.
					</p>
					<br/>
					<p><em>Robert Mahari*, Tobin South*, Alex 'Sandy' Pentland</em></p>
				</div>
				<div class="card">
					<h2 class="card-title">Competition Between AI Foundation Models: Dynamics and Policy Recommendations</h2>
					<figure><img src="images/AICompetition.png" alt="Technical Diagram"></figure>
					<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4493900" class="button">Working Paper on SSRN</a>
					<p>Generative AI is set to become a critical technology for our modern economies. If we are currently experiencing a strong, dynamic competition between the underlying foundation models, legal institutions have an important role to play in ensuring that the spring of foundation models does not turn into a winter with an ecosystem frozen by a handful of players.</p>
					<br/>
					<p><em>Thibault Schrepel, Alex 'Sandy' Pentland</em></p>
				</div>
				<div class="card">
					<h2 class="card-title">Unlocking the Power of Digital Commons: Data Cooperatives as a Pathway for Data Sovereign, Innovative and Equitable Digital Communities
					</h2>
					<figure><img src="images/UnlockingDigitalCommons.png"></figure>
					<a href="https://www.mdpi.com/2673-6470/3/3/11#" class="button">Article in Management of Digital Ecosystems</a>
					<p>This paper argues that data cooperatives can democratize digital resources and promote entrepreneurship, particularly for SMEs in small communities. It presents case studies to illustrate the transformative potential of such cooperatives and proposes a policy framework to support their practical implementation globally.
					</p>
					<br/>
					<p><em>BÃ¼hler et al.</em></p>
				</div>
			</div>
		  </div>
		</div>
	  </section>


	  	<!-- Bibtex Citation -->
		<!-- <section id="bibtex">
			<div class="bg-gray-100 p-4 rounded-sm overflow-auto text-black align-left">
			<h3 class="text-black text-2xl py-2">Bibtex Citation</h3>
			<pre class="text-sm">
@misc{South23CommunityTransformers,
	title={Secure Community Transformers: Private Pooled Data for LLMs},
	author={South, Tobin and Zyskind, Guy and Mahari, Robert and Hardjono, Thomas and Pentland, Alex 'Sandy'},
	year={2023},
	url={transformers.mit.edu}
}</pre>
			</div>
		</section>

	</div> -->

	<!-- Footer -->
	<footer class="bg-gray-800 text-white p-6">
	  <div class="flex items-center justify-between">
		<div class="flex items-center">
		  <img class="h-14 mr-5" src="images/CSlogo.png" alt="MIT Connection Science Logo">
		  <p>This is a project of MIT Connection Science, a group led by Alex 'Sandy' Pentland. The authors of
			this project are Tobin South, Guy Zyskind, Robert Mahari, Thomas Hardjono, and Sandy Pentland.
			Contact: tsouth@mit.edu</p>
		</div>
	  </div>
	</footer>

	<p class="copyright">&copy; MIT Connection Science 2023. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>

  </div>

  <!-- Scripts -->
  <script src="assets/js/jquery.min.js"></script>
  <script src="assets/js/jquery.scrollex.min.js"></script>
  <script src="assets/js/jquery.scrolly.min.js"></script>
  <script src="assets/js/browser.min.js"></script>
  <script src="assets/js/breakpoints.min.js"></script>
  <script src="assets/js/util.js"></script>
  <script src="assets/js/main.js"></script>

</body>

</html>